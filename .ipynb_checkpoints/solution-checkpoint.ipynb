{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import baseline_classifier as bsclf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content\n",
    "* [1 The assignment](#Introduction)\n",
    "* [2 The data](#TheData)\n",
    "* [3 Loading the data](#LoadingTheData)\n",
    "* [4 Exploratory data analysis](#ExploratoryDataAnalysis)\n",
    "    * [4.1 How many bank entries do companies have?](#HowManyBankEntries)\n",
    "    * [4.2 How many accounts do companies have?](#HowManyAccounts)\n",
    "    * [4.3 How many bank entries are there per account?](#HowManyBankEntriesPerAccount)\n",
    "    * [4.4 Summary of exploratory data analysis](#SummaryOfExploratory)\n",
    "    * [4.5 Looking into a single company in more detail](#SingleCompanyExploratory) \n",
    "* [5 Building the baseline classifier](#BuildingTheBaselineClassifier) (Part 1)\n",
    "* [6 Testing the baseline classifier](#TestingTheBaselineClassifier)\n",
    "    * [6.1 Testing on a single company](#TestingTheBaselineClassifierOnSingle)\n",
    "    * [6.2 Testing the classifier on each company](#TestingTheBaselineClassifierOnAll)\n",
    "    * [6.3 Summary of the baseline classifier](#SummaryOfTheBaselineClassifier)\n",
    "* [7 Taking advantage of the data across different companies](#TheSecondPart) (Part 2)\n",
    "    * [7.1 Mapping text onto features](#MappingText)\n",
    "\n",
    "# 1. The assignment<a id='Introduction'></a>\n",
    "This is my solution to the hiring assignment e-conomics posed the candidates applying for a position as a Data Scientist on the machine learning team. The assignment is descibed in detail [here](https://github.com/e-conomic/hiring-assigments/tree/master/autosuggest/bankrec-assignment).\n",
    "\n",
    "In short the assignment is to build a classifier that that can predict which account a given bank entry should be filed under. The assignment is divided into two parts. In the first part the candidate is asked to build and test a classifier __for each__ company. In the second part the candidate is asked to reflect on how one could build a classifier that works __for all__ companies. This would greatly increase the amount of training data and (perhaps) simply the process of classifying the bank entries.\n",
    "\n",
    "# 2. The data<a id='TheData'></a>\n",
    "The dataset consist of expenses from 100 random companies. For each all expenses that was booked in e-conomic (737017 bank entries in total) are provided. For each bank entry the following details are included as columns in the dataset:\n",
    "* **CompanyId**: The identifyer of the company to help you slice and dice the data in the right way.\n",
    "* **BankEntryDate (feature)**: The date of the financial transaction.\n",
    "* **BankEntryText (feature)**: The text following along with the financial transaction. This is typically machine generated, but in case of manual transactions they may be manually written by a human.\n",
    "* **BankEntryAmount (feature)**: The amount of the financial transaction. Expenses are negative, earnings are positive.\n",
    "* **AccountNumber (target)**: The account number. The uniquely identifies an account, and can therefore be used as the target variable / the class that we want to predict.\n",
    "* **AccountName**: The name of the account.\n",
    "* **AccountTypeName**: The type of the account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading and inspecting the data<a id='LoadingTheData'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/bank_expenses_obfuscated.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 737017 entries.\n",
    "\n",
    "Let's look at the first 5 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Exploratory data analysis<a id='ExploratoryDataAnalysis'></a>\n",
    "The goal is to get a better understanding of the data before I build a simple classifier that can work as a baseline for more complicated classifiers.\n",
    "## 4.1 How many bank entries do the companies have? <a id='HowManyBankEntries'></a>\n",
    "Since the input to the classifier will be a bank entry, we should understand how many entries each company has. This way we can get an idea about how data intensive we can allow our classifiers to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "companies = data['CompanyId'].unique()\n",
    "\n",
    "kk = 0\n",
    "numBankEntries = np.zeros((100,1))\n",
    "for company in companies:\n",
    "    numBankEntriesTemp = data[data.CompanyId==company].count()[0]\n",
    "    numBankEntries[kk] = numBankEntriesTemp\n",
    "    kk += 1\n",
    "    \n",
    "plt.bar(range(0,100),numBankEntries)\n",
    "plt.xlabel('Company index')\n",
    "plt.ylabel('number of bank entries for company')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by far the majority of bank entries are located with just a single company! This happens to be the 13th company in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(numBankEntries[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So just one of the companies has about 90 of the entire dataset!**\n",
    "\n",
    "It would be tempting to contine the analysis using this company, but it would be very representative of the average company.\n",
    "\n",
    "Let have a closer look at some of the other companies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(range(20,100),numBankEntries[20:100])\n",
    "plt.xlabel('Company index')\n",
    "plt.ylabel('number of bank entries for company')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that it is much more common to have close to 1000 entries or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 How many accounts do the companies have? <a id='HowManyAccounts'></a>\n",
    "Since I am building a classifier for each company it is important to know how many accounts each company has. This is also important for the second part of the assigment, since builder a classifier that works for all companies might be difficult if the number of accounts varies a lot between companies.\n",
    "\n",
    "Below I show the number of accounts for each company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kk = 0\n",
    "numAccounts = np.zeros((100,1))\n",
    "for company in companies:\n",
    "    company_data = data[data.CompanyId==company]\n",
    "    numAccountsUnique = company_data['AccountNumber'].unique()\n",
    "    numAccounts[kk] = numAccountsUnique.shape[0]\n",
    "    kk += 1\n",
    "    \n",
    "plt.bar(range(0,100),numAccounts)\n",
    "plt.xlabel('Company index')\n",
    "plt.ylabel('number of accounts for company')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of accounts the companies have varies greatly.\n",
    "\n",
    "A histogram of the number of accounts makes this point more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(numAccounts)\n",
    "plt.xlabel('number of accounts')\n",
    "plt.ylabel('number of companies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most companies have between 10 and 50 accounts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Do companies with more bank entries also have more accounts?<a id='HowManyBankEntriesPerAccount'></a>\n",
    "Ok. So the number of bank entries and accounts varies between companies. If companies with more accounts also have more bank entries, it might make classification easier. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(numBankEntries,numAccounts)\n",
    "plt.axis([0, 2000, 0, 120])\n",
    "plt.xlabel('number of bank entries')\n",
    "plt.ylabel('number of accounts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it does seem that there is a correlation between number of accounts and number of bank entries, but there is a lot of variability. \n",
    "\n",
    "How many bank entries are there per account on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bankEntriesPerAccount = numBankEntries/numAccounts\n",
    "plt.bar(range(0,100),bankEntriesPerAccount)\n",
    "plt.axis([0, 100, 0, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that quite a lot of the companies have fewer than 10 bank entries per account. This means that if we want to train a classifier per account per company, we had better use a classification model that does not need a lot of data to give good results.\n",
    "\n",
    "## 4.4 Summary of exploratory data analysis<a id='SummaryOfExploratory'></a> \n",
    "* The data contains 100 companies, and 737017 bank entries. Of these **90% (667021/737017) are from a single company!** It is much more common for a company to have close to 1000 bank entries.\n",
    "* Many companies have **between 10 and 50 accounts**.\n",
    "* Many of the companies have **fewer than 10 bank entries per account**, on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Looking at a single company in more detail<a id='SingleCompanyExploratory'></a>\n",
    "Above I look into the distribution of bank entries and bank accounts across the different companies. This gave a rough idea about what to expect from the data. However, since we are building a classifier for each company, understanding how the bank entries are distributed within a company is important.\n",
    "\n",
    "I will start by looking a the data for a single company. I will use company **int:7cb070e**.\n",
    "\n",
    "I am looking for the answer to the following questions:\n",
    "* How many of the bank entry texts are unique?\n",
    "* How are the bank entries distributed across the different accounts?\n",
    "\n",
    "### 4.5.1 Selecting the data for the company ID int:7cb070e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_df = data[data.CompanyId=='int:7cb070e']\n",
    "company_df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 How many bank entries does the company have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the company has a total of **808 bank entries**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 How many of the bank  entry texts are unique?<a id='HowManyBankEntriesAreUnique'></a>\n",
    "The number of unique bank entry text is important because I would like to use this feature for the baseline classifier.\n",
    "\n",
    "First I find all the unique **BankEntryText** for the Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BankEntryText = company_df['BankEntryText'].unique()\n",
    "numUniqueBankEntries = BankEntryText.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the company has a total of **808 bank entries**, finding that **320 of them are unique** is not great. If they are unique it does not leave us much to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 How many accounts does the company have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AccountNumber = company_df['AccountNumber'].unique()\n",
    "numUniqueAccounts = AccountNumber.shape[0]\n",
    "print(numUniqueAccounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company has **92 accounts**\n",
    "\n",
    "### 4.5.5 How are the bank entries distributed across the different accounts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bakEntriesPerAccount = np.zeros(AccountNumber.shape)\n",
    "kk=0\n",
    "for item in AccountNumber:\n",
    "    temp_bakEntriesPerAccount = company_df[company_df.AccountNumber==item].count()[0]\n",
    "    bakEntriesPerAccount[kk] = temp_bakEntriesPerAccount\n",
    "    kk += 1\n",
    "\n",
    "plt.bar(range(0,AccountNumber.shape[0]),bakEntriesPerAccount)\n",
    "plt.xlabel('Account index')\n",
    "plt.ylabel('Number of bank entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that most of the bank entries are filed under just a few of the accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.5 Summary of the exploratory analysis of a single company\n",
    "In conclusion: We can expect the majority of the of the transactions to fall within a small number (~5 our of 31) of the accounts. This is usefull to know when building a classifier. It tells us that if we can build a classifier that correctly classifies to the most used accounts we should be able to get a decent accuracy of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Building a baseline classifier<a id='BuildingTheBaselineClassifier'></a>\n",
    "The exploratory analysis presented above suggests that a reasonable baseline would be to establish the frequency of each **speciic** bank entry going into a spefic account. That is, I want to calculate the following: Given a **BankEntryText** what is the probability that it is classified as **AccountNumber**. When I have **P** for each **AccountNumber**, I can sort by **P** and use that as my classifier whenever I encounter a **BankEntryText** that is allready in the training data. \n",
    "\n",
    "The classifier basically says: Put the bank entry where you usually put it. \n",
    "\n",
    "It will not be perfect and it only uses a single feature, but it is a good baseline. Any classification system I build should at least be able to beat this raw probabalistic appraoch.\n",
    "\n",
    "For this I will continue to use the company with Conpanyid **int:a055470**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Etablishing the probabilities\n",
    "I will use the following vectorization: I create a matrix containing the unique bank entries as rows and the bank accounts as columns. That is, it will be a matrix with the shape: __num unique banke entries x num bank account__.\n",
    "\n",
    "Each unique bank entry will be a vector of length **number of bank accounts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myMatrix = np.zeros((numUniqueBankEntries,numUniqueAccounts))\n",
    "\n",
    "kk = 0\n",
    "for bankEntry in BankEntryText:\n",
    "    test = company_df[company_df.BankEntryText == bankEntry]\n",
    "    iteration = test['AccountNumber']\n",
    "    \n",
    "    for item in iteration:\n",
    "        accountIndex = AccountNumber == item\n",
    "        myMatrix[kk,:] = myMatrix[kk,:] + accountIndex\n",
    "    \n",
    "    kk += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have established a matrix containing the information we want. For each **unique BankEntryText** it tell us which accounts these bank entries have been classified to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(1-myMatrix[0:20,:],\n",
    "            cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.xlabel('Account index')\n",
    "plt.ylabel('Unique Bank Entry Text index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some of the **unique BankEntries** to different accounts. Let us have a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myMatrix[5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So some of the **unique BankEntries** do indeed go to different accounts.\n",
    "\n",
    "The simplest version of the classifier takes the maximum of the elements for each row in the matrice and classifies the **unique BankEntry** as belonging to that account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing the baseline classifier <a id='TestingTheBaselineClassifier'></a> \n",
    "## 6.1 Testing on a single company <a id='TestingTheBaselineClassifierOnSingle'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide the dataset into 80% train set and 20% test set\n",
    "percentTrainSize = 0.8\n",
    "trainSize = int(round(percentTrainSize*company_df.shape[0]))\n",
    "testSize = int(company_df.shape[0]-trainSize)\n",
    "\n",
    "train_df = company_df.tail(trainSize)\n",
    "test_df = company_df.head(testSize)\n",
    "\n",
    "# Build the matrice on the train set\n",
    "trainMatrix = np.zeros((numUniqueBankEntries,numUniqueAccounts))\n",
    "kk = 0\n",
    "for bankEntry in BankEntryText:\n",
    "    temp_df = train_df[train_df.BankEntryText == bankEntry]\n",
    "    iteration = temp_df['AccountNumber']\n",
    "    for item in iteration:\n",
    "        accountIndex = AccountNumber == item\n",
    "        trainMatrix[kk,:] = trainMatrix[kk,:] + accountIndex\n",
    "    kk += 1\n",
    "    \n",
    "# Find the maximal element in the matrice and save a dictionary that contains BankEntry string and Account number\n",
    "indices = np.zeros(len(trainMatrix))\n",
    "for row in range(0,len(trainMatrix)):\n",
    "    index = np.where(trainMatrix[row,:]==max(trainMatrix[row,:]))\n",
    "    indices[row] = index[0][0]\n",
    "    #trainMatrix[row,index][0][0]\n",
    "\n",
    "# Making the dictionary\n",
    "kk=0\n",
    "bankEntryTextToAccountNumber = {}\n",
    "for bankEntry in BankEntryText:\n",
    "    bankEntryTextToAccountNumber[bankEntry] = AccountNumber[indices[kk]]\n",
    "    kk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = np.zeros((testSize,1))\n",
    "kk = 0\n",
    "for account in test_df['AccountNumber']:\n",
    "    y_test[kk] = account\n",
    "    kk += 1\n",
    "    \n",
    "kk = 0\n",
    "y_predict = np.zeros((testSize,1))\n",
    "for text in test_df['BankEntryText']:\n",
    "    y_predict[kk] = bankEntryTextToAccountNumber[text]\n",
    "    kk += 1\n",
    "\n",
    "numCorrect = float(sum(y_predict==y_test))\n",
    "accuracy = numCorrect/testSize\n",
    "\n",
    "print('Number of test cases is: ' + str(testSize))\n",
    "print('number of correct predictions is: ' + str(numCorrect))\n",
    "print('The accuracy is: ' + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a base line that isn't bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Testing the classifier on each company<a id='TestingTheBaselineClassifierOnAll'></a>\n",
    "Above we say that for the specific company the baseline classifier had an accuracy of 60%. Thats quite ok, but we have allready seen that the number of accounts and bank entries varies a lot between the companies. So how does the baseline do on **every single company?**\n",
    "\n",
    "Below I run the baseline classifier on every company using 80% of the data is training data. The 80% are the oldest 80 % of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(bsclf)\n",
    "\n",
    "all_test_sizes = np.zeros((100,1))\n",
    "all_num_correct = np.zeros((100,1))\n",
    "all_accuracies = np.zeros((100,1))\n",
    "kk=0\n",
    "for company in companies:\n",
    "    company_df = data[data.CompanyId == company]\n",
    "    train_size, test_size, num_correct, accuracy = bsclf.baseline_classifier(company_df)\n",
    "    \n",
    "    all_test_sizes[kk] = test_size\n",
    "    all_num_correct[kk] = num_correct\n",
    "    all_accuracies[kk] = accuracy\n",
    "    \n",
    "    kk += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at how the accuracy changes with test size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avgAccuracy = sum(allAccuracies)/len(allAccuracies)\n",
    "\n",
    "plt.plot(allTestSizes,allAccuracies,'or')\n",
    "plt.plot([0, 1000],[avgAccuracy, avgAccuracy],'-b')\n",
    "plt.axis([0, 1000, 0, 1])\n",
    "plt.xlabel('test size')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "print('The average accuracy is: ' + str(avgAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of variability in the accuracy! This is even true for the companies with more than 100 bank entries in the test set. However, above 200 bank entries in the test set the baseline classifier appears to deliver more consistent results. The average accuracy of 42% is not good, but it serves as a fine baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(allAccuracies)\n",
    "plt.ylabel('number of companies')\n",
    "plt.xlabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Summary of the baseline classifier<a id='SummaryOfTheBaselineClassifier'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 The second part<a id='TheSecondPart'></a>\n",
    "Making a classifier that can take advantage of data across different companies. The allows us to avoid the __cold start__ problem.\n",
    "\n",
    "## 7.1 Mapping text onto features<a id='MappingText'></a>\n",
    "One way to get around this is to build a classifier that is based on the name of the account name rather than the speficic account id. In this way, if a company open up a new account with a title that is allready known we would be able to use the information from other companies. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
